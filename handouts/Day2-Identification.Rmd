---
title: "Quantitative Methods -- Day 2: Identifcation"
author: "Harm H. Schuett"
date: "`r format(Sys.time(), '%d %B, %Y')`"
bibliography: ../literature/bibliography.bib
output: 
  html_notebook: 
    code_folding: none
    number_sections: yes
    toc: yes
---

> The problem is that regression is like a demon or djinn from folktale. It answers exactly that question that you asked it. Often you don't realize though that you asked the wrong question ~ paraphrasing Richard McElreath

**After-class Reading:** A sizable part of this handout utilizes the excellent review @Elwert.2014. It is really well done, so please read it after class. 

```{r}
library(igraph)
library(tibble)
```


# Identification 

> "Neatly dividing associations into their causal and spurious components is the task of identification analysis. A causal effect is said to be identified if it is possible, with ideal data (infinite sample size and no measurement error), to purge an observed association of all noncausal components such that only the causal effect of interest remains." -- [@Elwert.2014, p. 33] 

Whenever we design an empirical study, ideally we would like to make a **causal** claim. We would like to test whether more transparent corporate disclosure *leads* to lower cost-of-capital (spoiler: it depends), whether tax avoidance leads to more investment, resturing efforts increase firm value if accompanied by employee motivational interventions, etc. Most often we won't be able to do that, but this is the goal that we want to get as close as we can. We 

## Identification and Theory
> **"Identification analysis requires a theory (i.e., a model or assumptions) of how the data were generated."** [@Elwert.2014, p. 33] 

The above quote cannot be underestimated in its importance. With theory, we usually mean all the assumptions you have about how the data in front of you was generated. Another important thing to realize is that you always make such assumption when you perform an analysis. For example, the way you define variables, which variables you include into a regression equation, whether you use clustered standard errors, etc. Any empirical method choice you make corresponds to certain assumptions about how the data came to pass. As such you implicitely lay out a theory of the data generating process, even if you weren't aware of it. In fact, most low-quality empirical work can probably be characterized by either weak underlying theory, questionable statistical procedures or both. The simple reason is that if you don't have thought a while about the underlying data generating process, you don't really have a good grasp of the hypotheses you want to test, are more likely to make wrong assumptions, and are less aware of issues you need to adress in your research design. 

Unfortunately, as you all now theories can never be fully tested or confirmed. Most of your assumptions will always remain assumptions. Some are more plausible, some have a 99.99\% chance of being correct, and others are more contestable. If you paid close attention in research seminars for instance, then you will have probably noticed that a big part of discussions in research seminars is about underlying assumptions, like "What if your main effect is correlated with xyz?" Most assumptions are debatable and it is your job to defend why you chose them. It is your job to express your theory explicitly for other scholars to inspect and judge. During the four two years, researchers in the social sciences have found DAGs (Directed acyclical graphs) very useful for that purpose. It is a nice and intuitve way to argue about the data-generating model.

## Graph Theory to Reason about Identification Tactics
> "DAGs encode the analystâ€™s qualitative causal assumptions about the data-generating process in the population." -- [@Elwert.2014, p. 35] 

The following structure of directed acyclic graphs (DAGs) is based on @Pearl.2009. A nice survey for social scientists is @Elwert.2013. Such DAGS have only a few key elements:

1. Each *node* or point on it represents a random variable (observed or unobserved). Unobserved variables are sometimes marked with a hollow dot. It doesn't matter how the variables are distributied. 
1. Arrows (*edges*) represent **assumed** direct causal effects. That why we use arrows, causal effect always have a direction (even if it is assumed). And because they reflect directed effects and the future cannot cause the past, these graphs cannot have circles. 
1. **Missing** arrows means you assume that no direct causal link exists. This is sometimes the most debatable assumption. In econometrics we also call this an exclusion restriction. You will find that you need those in order to do any kind of identification -- if everything determines everything, there is no sense in trying to indentify isolated links. 

A full graph is for a lot of purposes sufficient description of your assumed theory. You can go even further and turn this into a probabilistic graph to estimate Bayesian Networks, but we won't go there. We just use this as a way of communicating theory amongst us. 

Let's look at the following figure as an example of a generic theory. Say we have a research question where we are interested in estimating the *causal* link between a variable *T* (it has become standard practice to call the main variable of interest the *treatment* for reasons we discussed before) and a outcome *Y*:

```{r}
Nodes <- tribble(
  ~nodes,                 ~x, ~y, 
  "Pre-T-Influence (X)",   0,  1,  
  "Treatment (T)",         4,  1,  
  "Y",                     6,  1,  
  "Mediator (Z)",          1,  0,
  "Unobserved (U)",        0, -1)
Edges <- tribble(
  ~from,                 ~to,
  "Pre-T-Influence (X)", "Treatment (T)",
  "Pre-T-Influence (X)", "Y",
  "Treatment (T)",        "Y",
  "Treatment (T)",        "Mediator (Z)",
  "Mediator (Z)",         "Y",
  "Unobserved (U)",       "Y",
  "Unobserved (U)",       "Pre-T-Influence (X)",
  "Unobserved (U)",       "Mediator (Z)")
plot(graph_from_data_frame(vertices=Nodes, d=Edges, directed=TRUE),
     vertex.color=c(rep("gray30", nrow(Nodes) -1), "white"), 
     vertex.size=7,
     label.font=2, vertex.size=30, vertex.label.cex=1.2,
     edge.arrow.size=0.5, edge.color="gray70", 
     vertex.label.color="gray30", vertex.label.dist=2,
     vertex.label.degree=c(-pi/2, -pi/2, 0, pi/2, pi/2))
```

This graph is a toy example of a theory (unobserved variables are labeled with a white dot). The theory says:

1. There are (only) 5 variables in all that need to be considered to understand the link between *T* and *Y*. 
1. It doesn't say that there aren't more determinants of *Y* (or *T* for that matter). But it explicitely says that they can be ignored, if we care only about the link between *T* and *Y*. All the other determinants of *Y* are not crucial (e.g., in a regression they represent the "random" error term).
1. There are two **causal** paths from *T* to *Y*: 
    - *T* -> *Y* (a direct effect)
    - *T* -> *Z* -> *Y* (an effect mediated through a mediating variable *Z*)
1. There are two **non-causal** paths between *T* and *Y*. Those are the key issues that if we cannot adress them, we cannot identify a causal link between *T* and *Y*:
    - *T* <- *X* <- *U* -> *Y*  (an unobserved confounder that drives variation in *T* and *Y*)
    - *T* -> *Z* <- *U* -> *Y*  (the confounder also affects the mediating variable *Z*)

So, it shoud be apparent that the key thing is to reason about *paths*. **Causal paths** are those were the the arrows always point aways from the treatment and towards the outcome. The total treatment effect is then the set of all causal paths. However, correlation is not causation, as we all no. And non-causal paths also induce correlation between *T* and *Y*. Which is why we care about them. In a way you can think about the identification problem as taking the correlation betwen *T* and *Y* and scrubbing it from all correlation that is induced by non-causal paths. What is left is the correlation from causal paths and only then can we interpret the correlation in our sample (e.g.,  regression coefficents) as indicating a causal effect.

In the case above, we cannot hope to identify a causal effect of *T* on *Y* unless we find a way to get rid of the influcence of *U*. In fact, "... all nonparametric identification problems can be classified as one of three underlying problems: overcontrol bias, confounding bias, and endogenous selection bias." [@Elwert.2014, p. 32]. And all three are can be characterized as arising from non-causal pathways. 

Pretty much 70\% of the remainder of this course is about different methods of how to deal with non-causal pathways. The rest is estimation techniques. If variables are observable, *conditioning* on selected variables can go a long way in blocking non-causal paths. Condition is a bit of a catch-all term, but it is an important concept. "conditioning refers to introducing information about a variable into the analysis by some means. In sociology, conditioning usually takes the form of controlling for a variable in a regression model, but it could also take the form of stratifying on a variable, performing a groupspecific analysis (thus conditioning on group membership), or collecting data selectively (e.g., excluding children, prisoners, retirees, or nonrespondents from a survey)."" [@Elwert.2014, p. 35]. If you condition on the wrong variables however, you can **induce** non-causal correlation (e.g., by including certain post treatment variables in your regression). This is the cause of endogeneous selection bias, which we will talk about in great length later.

Let's go through all three indentification problems: overcontrol bias, confounding bias, and endogenous selection bias, look at examples and how to deal with them.

# Confounders and Correlated Ommitted Variable Bias
> "Confounding originates from common causes, whereas endogenous selection originates from common outcomes."" -- [@Elwert.2014, p. 32]




## Graph Representation of the Problem
http://socviz.co/

## Mathematical Derivation

## Examples

# Endogenous Selection Bias

(See @Elwert.2014, @Acharya.2016, @Gelman.2007, pp. 188-194, and @Angrist.2008, pp. 64-68)

## Graph Representation of the Problem

So, far we have mainly talked about confounders in the sense of attributes or influences that occured logically either before the Treatment (or our variable of interest) or are independent of the Treatment. 

However, there often some influences of interest that logically occur after the treatment. For example if we consider a mediating influence like below:

```{r}
Nodes <- tribble(
  ~nodes,                 ~x, ~y, 
  "Pre-T-Confounder (W)", -2,  1,  
  "Treatment (X)",        -1,  0,  
  "Y",                     1,  0,  
  "Mediator (Z)",          0, -1,
  "All Else (u)",          2,  1)
Edges <- tribble(
  ~from,                 ~to,
  "Pre-T-Confounder (W)", "Treatment (X)",
  "Pre-T-Confounder (W)", "Y",
  "Treatment (X)",        "Y",
  "Treatment (X)",        "Mediator (Z)",
  "Mediator (Z)",         "Y",
  "All Else (u)",         "Y")
plot(graph_from_data_frame(vertices=Nodes, d=Edges, directed=TRUE),
     vertex.color="gray30", vertex.size=7,
     label.font=2, vertex.size=30, vertex.label.cex=1.2,
     edge.arrow.size=0.5, edge.color="gray70", 
     vertex.label.color="gray30", vertex.label.dist=2,
     vertex.label.degree=c(-pi/2,pi/2, 0, pi/2, -pi/2))
```

In such a scenario (we assume) that there exists a mediating variable. Something that is affected by the *treatment* (*X*) and changes the outcome *Y* as a result. In this scenario, *X* changes *Y* in two ways: (1) via a direct effect and (2) via a detour through the mediator (*M*).  

Now what happens if you put the Mediator into the regression? 

$$Y = a_0 + a_1X + a_2W+a_3M+u$$

This is called **conditioning on a post-treatment outcome** and it is actually often a bad idea, because reality is usually not as simple as the assumed relations above. Let's discuss why and learn more about regression and inference.

First of all, why would you want to put *M* in here? Actually, one sees this quite often, especially in older studies where quite frankly most applied researchers weren't really aware of this problem. The main reason you see this is if researchers want to see whether a mediator exists and what the *direct* effect of *X* is on *Y*. And in the scenario above you can actually do this. 

Unfortunately, quite often, theory and/or common sense sugegst that we have a different situation: 

```{r}
Nodes <- tribble(
  ~nodes,                 ~x, ~y, 
  "Pre-T-Confounder (W)", -2,  2,  
  "Treatment (X)",        -1,  0,  
  "Y",                     1,  0,  
  "Mediator (Z)",          0, -1,
  "Interm. Confounder (V)",0,  1,
  "All Else (u)",          2,  2)
Edges <- tribble(
  ~from,                  ~to,
  "Pre-T-Confounder (W)",  "Treatment (X)",
  "Pre-T-Confounder (W)",  "Y",
  "Treatment (X)",         "Y",
  "Treatment (X)",         "Mediator (Z)",
  "Interm. Confounder (V)","Mediator (Z)",
  "Interm. Confounder (V)","Y",
  "Mediator (Z)",          "Y",
  "All Else (u)",          "Y")
g1 <- graph_from_data_frame(vertices=Nodes, d=Edges, directed=TRUE)
E(g1)$color <- "gray70"
E(g1)$color[5:6] <- "red"
plot(g1,
     vertex.color="gray30", vertex.size=7,
     label.font=2, vertex.size=30, vertex.label.cex=1.2,
     edge.arrow.size=0.5, # edge.color="gray70", 
     vertex.label.color="gray30", vertex.label.dist=2,
     vertex.label.degree=c(-pi/2,pi/2, 0, pi/2, -pi/2, -pi/2))
```

As @Acharya.2016, p.518 puts it:

> "Conditioning on a mediator results in selection bias unless all of the intermediate confounders are included as well (sometimes called M bias), but including them means including posttreatment variables (posttreatment bias)."

The reference posttreatment bias occurs, if the situation is further complicated like this: 

```{r}
Nodes <- tribble(
  ~nodes,                 ~x, ~y, 
  "Pre-T-Confounder (W)", -2,  2,  
  "Treatment (X)",        -1,  0,  
  "Y",                     1,  0,  
  "Mediator (Z)",          0, -1,
  "Interm. Confounder (V)",0,  1,
  "All Else (u)",          2,  2)
Edges <- tribble(
  ~from,                  ~to,
  "Pre-T-Confounder (W)",  "Treatment (X)",
  "Pre-T-Confounder (W)",  "Y",
  "Treatment (X)",         "Y",
  "Treatment (X)",         "Mediator (Z)",
  "Treatment (X)",         "Interm. Confounder (V)",
  "Interm. Confounder (V)","Mediator (Z)",
  "Interm. Confounder (V)","Y",
  "Mediator (Z)",          "Y",
  "All Else (u)",          "Y")
g1 <- graph_from_data_frame(vertices=Nodes, d=Edges, directed=TRUE)
E(g1)$color <- "gray70"
E(g1)$color[5:7] <- "red"
plot(g1,
     vertex.color="gray30", vertex.size=7,
     label.font=2, vertex.size=30, vertex.label.cex=1.2,
     edge.arrow.size=0.5, # edge.color="gray70", 
     vertex.label.color="gray30", vertex.label.dist=2,
     vertex.label.degree=c(-pi/2,pi/2, 0, pi/2, -pi/2, -pi/2))
```

In this case, including *Z* into the regression ($Y = a_0 + a_1X + a_2W+a_3M+a_4Z+u$) won't help estimating the impact of *X* on *Y*, since we would block one part of that impact: *X->Z->Y*. In such situations, we would need to resort to what is called sequential g-estimation, which is a two-stage procedure. 

## Examples

Let's see what could be the problem; let's simulate an intermediate variable bias [@Rosenbaum.1984]

## Summary

The preceding discussion should have highlighted a few things:

1. You need theory of some sort for sound empirical analysis: Only theory can help you make sound assumptions about how the causal graph could look like. 
1. You need to be very careful with post-treatment variables. Only include them if you really need to separate effects. 
1. Be very careful if you are after mediator or direct effects, in some cases you might actually be better of resorting to structural equation models (which, we will take a quick glance at in the last section).



# References
